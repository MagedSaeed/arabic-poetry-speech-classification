{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 205884,
     "status": "ok",
     "timestamp": 1635951380569,
     "user": {
      "displayName": "Maged Saeed",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghfl38dqLtgiKi2-s-gKPRT0lr9gXQd7UDqCF22lA=s64",
      "userId": "08011552846066909361"
     },
     "user_tz": -180
    },
    "id": "hLZPLV-qAmQq",
    "outputId": "2dadd197-cd05-4750-dc8c-4c1496e59cb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchaudio in /home/majed.alshaibani/.virtualenvs/arabic-speech-poetry-classification/lib/python3.8/site-packages (0.10.0)\n",
      "Requirement already satisfied: torch==1.10.0 in /home/majed.alshaibani/.virtualenvs/arabic-speech-poetry-classification/lib/python3.8/site-packages (from torchaudio) (1.10.0)\n",
      "Requirement already satisfied: typing-extensions in /home/majed.alshaibani/.virtualenvs/arabic-speech-poetry-classification/lib/python3.8/site-packages (from torch==1.10.0->torchaudio) (3.10.0.2)\n",
      "Requirement already satisfied: transformers in /home/majed.alshaibani/.virtualenvs/arabic-speech-poetry-classification/lib/python3.8/site-packages (4.12.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/majed.alshaibani/.virtualenvs/arabic-speech-poetry-classification/lib/python3.8/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: filelock in /home/majed.alshaibani/.virtualenvs/arabic-speech-poetry-classification/lib/python3.8/site-packages (from transformers) (3.3.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/majed.alshaibani/.virtualenvs/arabic-speech-poetry-classification/lib/python3.8/site-packages (from transformers) (1.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /home/majed.alshaibani/.virtualenvs/arabic-speech-poetry-classification/lib/python3.8/site-packages (from transformers) (0.1.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/majed.alshaibani/.virtualenvs/arabic-speech-poetry-classification/lib/python3.8/site-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: sacremoses in /home/majed.alshaibani/.virtualenvs/arabic-speech-poetry-classification/lib/python3.8/site-packages (from transformers) (0.0.46)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /home/majed.alshaibani/.virtualenvs/arabic-speech-poetry-classification/lib/python3.8/site-packages (from transformers) (0.10.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/majed.alshaibani/.virtualenvs/arabic-speech-poetry-classification/lib/python3.8/site-packages (from transformers) (2021.11.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/majed.alshaibani/.virtualenvs/arabic-speech-poetry-classification/lib/python3.8/site-packages (from transformers) (21.2)\n",
      "Requirement already satisfied: requests in /home/majed.alshaibani/.virtualenvs/arabic-speech-poetry-classification/lib/python3.8/site-packages (from transformers) (2.26.0)\n",
      "Requirement already satisfied: typing-extensions in /home/majed.alshaibani/.virtualenvs/arabic-speech-poetry-classification/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
      "Requirement already satisfied: joblib in /home/majed.alshaibani/.virtualenvs/arabic-speech-poetry-classification/lib/python3.8/site-packages (from sacremoses->transformers) (1.1.0)\n",
      "Requirement already satisfied: click in /home/majed.alshaibani/.virtualenvs/arabic-speech-poetry-classification/lib/python3.8/site-packages (from sacremoses->transformers) (8.0.3)\n",
      "Requirement already satisfied: six in /home/majed.alshaibani/.virtualenvs/arabic-speech-poetry-classification/lib/python3.8/site-packages (from sacremoses->transformers) (1.16.0)\n",
      "Requirement already satisfied: pyparsing<3,>=2.0.2 in /home/majed.alshaibani/.virtualenvs/arabic-speech-poetry-classification/lib/python3.8/site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in /home/majed.alshaibani/.virtualenvs/arabic-speech-poetry-classification/lib/python3.8/site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/majed.alshaibani/.virtualenvs/arabic-speech-poetry-classification/lib/python3.8/site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in /home/majed.alshaibani/.virtualenvs/arabic-speech-poetry-classification/lib/python3.8/site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/majed.alshaibani/.virtualenvs/arabic-speech-poetry-classification/lib/python3.8/site-packages (from requests->transformers) (1.26.7)\n",
      "Requirement already satisfied: datasets in /home/majed.alshaibani/.virtualenvs/arabic-speech-poetry-classification/lib/python3.8/site-packages (1.15.1)\n",
      "Requirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in /home/majed.alshaibani/.virtualenvs/arabic-speech-poetry-classification/lib/python3.8/site-packages (from datasets) (6.0.0)\n",
      "Requirement already satisfied: multiprocess in /home/majed.alshaibani/.virtualenvs/arabic-speech-poetry-classification/lib/python3.8/site-packages (from datasets) (0.70.12.2)\n",
      "Requirement already satisfied: aiohttp in /home/majed.alshaibani/.virtualenvs/arabic-speech-poetry-classification/lib/python3.8/site-packages (from datasets) (3.8.0)\n",
      "Requirement already satisfied: pandas in /home/majed.alshaibani/.virtualenvs/arabic-speech-poetry-classification/lib/python3.8/site-packages (from datasets) (1.3.4)\n",
      "Requirement already satisfied: packaging in /home/majed.alshaibani/.virtualenvs/arabic-speech-poetry-classification/lib/python3.8/site-packages (from datasets) (21.2)\n",
      "Requirement already satisfied: dill in /home/majed.alshaibani/.virtualenvs/arabic-speech-poetry-classification/lib/python3.8/site-packages (from datasets) (0.3.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/majed.alshaibani/.virtualenvs/arabic-speech-poetry-classification/lib/python3.8/site-packages (from datasets) (2.26.0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /home/majed.alshaibani/.virtualenvs/arabic-speech-poetry-classification/lib/python3.8/site-packages (from datasets) (2021.10.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /home/majed.alshaibani/.virtualenvs/arabic-speech-poetry-classification/lib/python3.8/site-packages (from datasets) (0.1.0)\n",
      "Requirement already satisfied: xxhash in /home/majed.alshaibani/.virtualenvs/arabic-speech-poetry-classification/lib/python3.8/site-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/majed.alshaibani/.virtualenvs/arabic-speech-poetry-classification/lib/python3.8/site-packages (from datasets) (4.62.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/majed.alshaibani/.virtualenvs/arabic-speech-poetry-classification/lib/python3.8/site-packages (from datasets) (1.20.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/majed.alshaibani/.virtualenvs/arabic-speech-poetry-classification/lib/python3.8/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/majed.alshaibani/.virtualenvs/arabic-speech-poetry-classification/lib/python3.8/site-packages (from aiohttp->datasets) (1.7.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/majed.alshaibani/.virtualenvs/arabic-speech-poetry-classification/lib/python3.8/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /home/majed.alshaibani/.virtualenvs/arabic-speech-poetry-classification/lib/python3.8/site-packages (from aiohttp->datasets) (2.0.7)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/majed.alshaibani/.virtualenvs/arabic-speech-poetry-classification/lib/python3.8/site-packages (from aiohttp->datasets) (4.0.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/majed.alshaibani/.virtualenvs/arabic-speech-poetry-classification/lib/python3.8/site-packages (from aiohttp->datasets) (5.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/majed.alshaibani/.virtualenvs/arabic-speech-poetry-classification/lib/python3.8/site-packages (from aiohttp->datasets) (21.2.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/majed.alshaibani/.virtualenvs/arabic-speech-poetry-classification/lib/python3.8/site-packages (from pandas->datasets) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/majed.alshaibani/.virtualenvs/arabic-speech-poetry-classification/lib/python3.8/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pyparsing<3,>=2.0.2 in /home/majed.alshaibani/.virtualenvs/arabic-speech-poetry-classification/lib/python3.8/site-packages (from packaging->datasets) (2.4.7)\n",
      "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in /home/majed.alshaibani/.virtualenvs/arabic-speech-poetry-classification/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/majed.alshaibani/.virtualenvs/arabic-speech-poetry-classification/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/majed.alshaibani/.virtualenvs/arabic-speech-poetry-classification/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (1.26.7)\n",
      "Requirement already satisfied: pyyaml in /home/majed.alshaibani/.virtualenvs/arabic-speech-poetry-classification/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n",
      "Requirement already satisfied: filelock in /home/majed.alshaibani/.virtualenvs/arabic-speech-poetry-classification/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.3.2)\n",
      "Requirement already satisfied: typing-extensions in /home/majed.alshaibani/.virtualenvs/arabic-speech-poetry-classification/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.10.0.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/majed.alshaibani/.virtualenvs/arabic-speech-poetry-classification/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: lang_trans in /home/majed.alshaibani/.virtualenvs/arabic-speech-poetry-classification/lib/python3.8/site-packages (0.6.0)\n",
      "Requirement already satisfied: arabic_reshaper in /home/majed.alshaibani/.virtualenvs/arabic-speech-poetry-classification/lib/python3.8/site-packages (2.1.3)\n",
      "Requirement already satisfied: future in /home/majed.alshaibani/.virtualenvs/arabic-speech-poetry-classification/lib/python3.8/site-packages (from arabic_reshaper) (0.18.2)\n",
      "Requirement already satisfied: setuptools in /home/majed.alshaibani/.virtualenvs/arabic-speech-poetry-classification/lib/python3.8/site-packages (from arabic_reshaper) (44.0.0)\n",
      "Requirement already satisfied: python-bidi in /home/majed.alshaibani/.virtualenvs/arabic-speech-poetry-classification/lib/python3.8/site-packages (0.4.2)\n",
      "Requirement already satisfied: six in /home/majed.alshaibani/.virtualenvs/arabic-speech-poetry-classification/lib/python3.8/site-packages (from python-bidi) (1.16.0)\n",
      "Requirement already satisfied: pydub in /home/majed.alshaibani/.virtualenvs/arabic-speech-poetry-classification/lib/python3.8/site-packages (0.25.1)\n",
      "Requirement already satisfied: soundfile in /home/majed.alshaibani/.virtualenvs/arabic-speech-poetry-classification/lib/python3.8/site-packages (0.10.3.post1)\n",
      "Requirement already satisfied: cffi>=1.0 in /home/majed.alshaibani/.virtualenvs/arabic-speech-poetry-classification/lib/python3.8/site-packages (from soundfile) (1.15.0)\n",
      "Requirement already satisfied: pycparser in /home/majed.alshaibani/.virtualenvs/arabic-speech-poetry-classification/lib/python3.8/site-packages (from cffi>=1.0->soundfile) (2.20)\n",
      "Requirement already satisfied: jiwer in /home/majed.alshaibani/.virtualenvs/arabic-speech-poetry-classification/lib/python3.8/site-packages (2.2.1)\n",
      "Requirement already satisfied: python-Levenshtein==0.12.2 in /home/majed.alshaibani/.virtualenvs/arabic-speech-poetry-classification/lib/python3.8/site-packages (from jiwer) (0.12.2)\n",
      "Requirement already satisfied: setuptools in /home/majed.alshaibani/.virtualenvs/arabic-speech-poetry-classification/lib/python3.8/site-packages (from python-Levenshtein==0.12.2->jiwer) (44.0.0)\n",
      "Requirement already satisfied: PyArabic in /home/majed.alshaibani/.virtualenvs/arabic-speech-poetry-classification/lib/python3.8/site-packages (0.6.14)\n",
      "Requirement already satisfied: six>=1.14.0 in /home/majed.alshaibani/.virtualenvs/arabic-speech-poetry-classification/lib/python3.8/site-packages (from PyArabic) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchaudio\n",
    "!pip install transformers\n",
    "!pip install datasets\n",
    "!pip install lang_trans\n",
    "!pip install arabic_reshaper\n",
    "!pip install python-bidi\n",
    "!pip install pydub\n",
    "!pip install soundfile\n",
    "!pip install jiwer\n",
    "!pip install PyArabic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 5872,
     "status": "ok",
     "timestamp": 1635951389881,
     "user": {
      "displayName": "Maged Saeed",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghfl38dqLtgiKi2-s-gKPRT0lr9gXQd7UDqCF22lA=s64",
      "userId": "08011552846066909361"
     },
     "user_tz": -180
    },
    "id": "7eFqbmnnAL-n"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%` not found.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import json\n",
    "import torch\n",
    "import jiwer\n",
    "import logging\n",
    "import librosa\n",
    "import datasets\n",
    "import itertools\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "import transformers\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "import seaborn as sns\n",
    "import torch.nn as nn\n",
    "import soundfile as sf\n",
    "import arabic_reshaper\n",
    "from pyarabic import araby\n",
    "from packaging import version\n",
    "from pydub import AudioSegment\n",
    "import matplotlib.pyplot as plt\n",
    "from trainer import CTCTrainer\n",
    "from pydub.utils import mediainfo\n",
    "from argparse import ArgumentParser\n",
    "from torch.nn import functional as F\n",
    "from contextlib import contextmanager\n",
    "from bidi.algorithm import get_display\n",
    "from lang_trans.arabic import buckwalter\n",
    "from dataclasses import dataclass, field\n",
    "from datasets import load_dataset, Dataset\n",
    "from sklearn.metrics import accuracy_score\n",
    "from models import Wav2Vec2ClassificationModel\n",
    "from processors import CustomWav2Vec2Processor\n",
    "from typing import Any, Dict, List, Optional, Union\n",
    "from transformers import HfArgumentParser,TrainingArguments\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from transformers.trainer_utils import get_last_checkpoint, is_main_process\n",
    "from transformers import is_apex_available,set_seed ,Trainer,Wav2Vec2FeatureExtractor\n",
    "from arg_parsers import DataTrainingArguments, ModelArguments, DataCollatorCTCWithPadding\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor, Wav2Vec2Model,Wav2Vec2PreTrainedModel\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 9944,
     "status": "ok",
     "timestamp": 1635951403156,
     "user": {
      "displayName": "Maged Saeed",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghfl38dqLtgiKi2-s-gKPRT0lr9gXQd7UDqCF22lA=s64",
      "userId": "08011552846066909361"
     },
     "user_tz": -180
    },
    "id": "B4BretRa_kHc"
   },
   "outputs": [],
   "source": [
    "!cp -r /content/drive/MyDrive/KFUPM-Master/ICS606/Dataset/All_poems.zip ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fWT8mSb1ADRU"
   },
   "outputs": [],
   "source": [
    "if os.path.exists('dataset'):\n",
    "  if len(os.listdir('dataset')) == 0:\n",
    "    os.system('unzip All_poems.zip -d dataset')\n",
    "else:\n",
    "  os.system('unzip All_poems.zip -d dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q0W2S-XtAGhi"
   },
   "outputs": [],
   "source": [
    "!mkdir -p dataset_wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G7f5oPvDCx4L"
   },
   "outputs": [],
   "source": [
    "!cp /content/drive/MyDrive/KFUPM-Master/ICS606/Dataset/testset.csv .\n",
    "!cp /content/drive/MyDrive/KFUPM-Master/ICS606/Dataset/trainset.csv .\n",
    "!cp /content/drive/MyDrive/KFUPM-Master/ICS606/Dataset/valset.csv ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jv2ZeRsUAIF9"
   },
   "outputs": [],
   "source": [
    "metadata_test_path = 'testset.csv'\n",
    "metadata_train_path = 'trainset.csv'\n",
    "metadata_val_path = 'valset.csv'\n",
    "dataset_folder = 'dataset'\n",
    "dataset_wav_folder = 'dataset_wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fytnRuUYAwnr"
   },
   "outputs": [],
   "source": [
    "train_metadata = pd.read_csv(metadata_train_path)\n",
    "test_metadata = pd.read_csv(metadata_test_path)\n",
    "val_metadata = pd.read_csv(metadata_val_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 596712,
     "status": "ok",
     "timestamp": 1634414983222,
     "user": {
      "displayName": "Maged Saeed",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghfl38dqLtgiKi2-s-gKPRT0lr9gXQd7UDqCF22lA=s64",
      "userId": "08011552846066909361"
     },
     "user_tz": -180
    },
    "id": "7_KVXrgqA11f",
    "outputId": "c9a0519e-5df3-4741-edbe-fe8d4e15f97e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{44100, 48000}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_rates = set()\n",
    "for file_path in itertools.chain(\n",
    "    train_metadata['Utterance name'],\n",
    "    test_metadata['Utterance name'],\n",
    "    val_metadata['Utterance name']\n",
    "  ):\n",
    "  complete_path = f'{dataset_folder}/{file_path}'\n",
    "  complete_wav_path = f'{dataset_wav_folder}/{file_path}'\n",
    "  # os.system(f'ffmpeg -i {complete_path} {complete_wav_path}')\n",
    "  audio = AudioSegment.from_file(complete_path)\n",
    "  sample_rates.add(audio.frame_rate)\n",
    "  audio.export(f'{dataset_wav_folder}/{file_path}', format='wav')\n",
    "sample_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6FyjHsokns8Z"
   },
   "outputs": [],
   "source": [
    "# the following can be used\n",
    "# https://beta.quod.ai/github/huggingface/transformers?question_modal=true&question_public_id=8757&from_search=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LjctTq9YGN0b"
   },
   "outputs": [],
   "source": [
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "if is_apex_available():\n",
    "    from apex import amp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if version.parse(torch.__version__) >= version.parse(\"1.6\"):\n",
    "    _is_native_amp_available = True\n",
    "    from torch.cuda.amp import autocast\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## getting training arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = HfArgumentParser(\n",
    "        (ModelArguments, DataTrainingArguments, TrainingArguments)\n",
    "    )\n",
    "if len(sys.argv) == 2 and sys.argv[1].endswith(\".json\"):\n",
    "    # If we pass only one argument to the script and it's the path to a json file,\n",
    "    # let's parse it to get our arguments.\n",
    "    model_args, data_args, training_args = parser.parse_json_file(\n",
    "        json_file=os.path.abspath(sys.argv[1])\n",
    "    )\n",
    "else:\n",
    "    model_args, data_args, training_args = parser.parse_args_into_dataclasses()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## logging setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup logging\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    handlers=[logging.StreamHandler(sys.stdout)],\n",
    ")\n",
    "logger.setLevel(\n",
    "    logging.INFO if is_main_process(training_args.local_rank) else logging.WARN\n",
    ")\n",
    "\n",
    "# Log on each process the small summary:\n",
    "logger.warning(\n",
    "    f\"Process rank: {training_args.local_rank}, device: {training_args.device}, n_gpu: {training_args.n_gpu}\"\n",
    "    + f\"distributed training: {bool(training_args.local_rank != -1)}, 16-bits training: {training_args.fp16}\"\n",
    ")\n",
    "# Set the verbosity to info of the Transformers logger (on main process only):\n",
    "if is_main_process(training_args.local_rank):\n",
    "    transformers.utils.logging.set_verbosity_info()\n",
    "\n",
    "# Set seed before initializing model.\n",
    "set_seed(training_args.seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check for previous checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detecting last checkpoint.\n",
    "last_checkpoint = None\n",
    "if (\n",
    "    os.path.isdir(training_args.output_dir)\n",
    "    and training_args.do_train\n",
    "    and not training_args.overwrite_output_dir\n",
    "):\n",
    "    last_checkpoint = get_last_checkpoint(training_args.output_dir)\n",
    "    if last_checkpoint is None and len(os.listdir(training_args.output_dir)) > 0:\n",
    "        raise ValueError(\n",
    "            f\"Output directory ({training_args.output_dir}) already exists and is not empty. \"\n",
    "            \"Use --overwrite_output_dir to overcome.\"\n",
    "        )\n",
    "    elif last_checkpoint is not None:\n",
    "        logger.info(\n",
    "            f\"Checkpoint detected, resuming training at {last_checkpoint}. To avoid this behavior, change \"\n",
    "            \"the `--output_dir` or add `--overwrite_output_dir` to train from scratch.\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataset processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metadata = pd.read_csv(metadata_train_path)\n",
    "val_metadata = pd.read_csv(metadata_val_path)\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_metadata)\n",
    "eval_dataset = Dataset.from_pandas(val_metadata)\n",
    "feature_extractor = Wav2Vec2FeatureExtractor(\n",
    "    feature_size=1,\n",
    "    sampling_rate=16_000,\n",
    "    padding_value=0.0,\n",
    "    do_normalize=True,\n",
    "    return_attention_mask=True,\n",
    ")\n",
    "processor = CustomWav2Vec2Processor(feature_extractor=feature_extractor)\n",
    "model = Wav2Vec2ClassificationModel.from_pretrained(\n",
    "    \"bakrianoo/sinai-voice-ar-stt\",\n",
    "    attention_dropout=0.01,\n",
    "    hidden_dropout=0.01,\n",
    "    feat_proj_dropout=0.0,\n",
    "    mask_time_prob=0.05,\n",
    "    layerdrop=0.01,\n",
    "    gradient_checkpointing=True,\n",
    "    num_attention_heads=4,\n",
    ")\n",
    "\n",
    "if model_args.freeze_feature_extractor:\n",
    "    model.freeze_feature_extractor()\n",
    "\n",
    "if data_args.max_train_samples is not None:\n",
    "    train_dataset = train_dataset.select(range(data_args.max_train_samples))\n",
    "\n",
    "if data_args.max_val_samples is not None:\n",
    "    eval_dataset = eval_dataset.select(range(data_args.max_val_samples))\n",
    "# Preprocessing the datasets.\n",
    "# We need to read the aduio files as arrays and tokenize the targets.\n",
    "resamplers = {  # The dataset contains all the uncommented sample rates\n",
    "    48000: torchaudio.transforms.Resample(48000, 16000),\n",
    "    44100: torchaudio.transforms.Resample(44100, 16000),\n",
    "    # 32000: torchaudio.transforms.Resample(32000, 16000),\n",
    "}\n",
    "\n",
    "labels = {\n",
    "    bahr: bahr_index\n",
    "    for bahr_index, bahr in enumerate(sorted(set(train_metadata[\"Bahr\"])))\n",
    "}\n",
    "print(\"labels are:\", labels)\n",
    "print(\"len:\", len(labels))\n",
    "\n",
    "def speech_file_to_array_fn(batch):\n",
    "    start = 0\n",
    "    stop = 20\n",
    "    srate = 16_000\n",
    "    speech_array, sampling_rate = torchaudio.load(\n",
    "        f'../dataset_wav/{batch[\"Utterance name\"]}'\n",
    "    )\n",
    "    speech_array = speech_array[0]\n",
    "    batch[\"speech\"] = resamplers[sampling_rate](speech_array).squeeze().numpy()\n",
    "    batch[\"sampling_rate\"] = srate\n",
    "    batch[\"parent\"] = labels[batch[\"Bahr\"]]\n",
    "    return batch\n",
    "\n",
    "train_dataset = train_dataset.map(\n",
    "    speech_file_to_array_fn,\n",
    "    remove_columns=train_dataset.column_names,\n",
    "    num_proc=data_args.preprocessing_num_workers,\n",
    ")\n",
    "eval_dataset = eval_dataset.map(\n",
    "    speech_file_to_array_fn,\n",
    "    remove_columns=eval_dataset.column_names,\n",
    "    num_proc=data_args.preprocessing_num_workers,\n",
    ")\n",
    "\n",
    "def prepare_dataset(batch):\n",
    "    # check that all files have the correct sampling rate\n",
    "    assert (\n",
    "        len(set(batch[\"sampling_rate\"])) == 1\n",
    "    ), f\"Make sure all inputs have the same sampling rate of {processor.feature_extractor.sampling_rate}.\"\n",
    "    batch[\"input_values\"] = processor(\n",
    "        batch[\"speech\"], sampling_rate=batch[\"sampling_rate\"][0]\n",
    "    ).input_values\n",
    "    batch[\"labels\"] = batch[\"parent\"]\n",
    "    return batch\n",
    "\n",
    "train_dataset = train_dataset.map(\n",
    "    prepare_dataset,\n",
    "    remove_columns=train_dataset.column_names,\n",
    "    batch_size=training_args.per_device_train_batch_size,\n",
    "    batched=True,\n",
    "    num_proc=data_args.preprocessing_num_workers,\n",
    ")\n",
    "eval_dataset = eval_dataset.map(\n",
    "    prepare_dataset,\n",
    "    remove_columns=eval_dataset.column_names,\n",
    "    batch_size=training_args.per_device_train_batch_size,\n",
    "    batched=True,\n",
    "    num_proc=data_args.preprocessing_num_workers,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids.argmax(-1)\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    report = classification_report(labels, preds)\n",
    "    matrix = confusion_matrix(labels, preds)\n",
    "    print(matrix)\n",
    "    return {\"accuracy\": acc}\n",
    "# Data collator\n",
    "data_collator = DataCollatorCTCWithPadding(processor=processor, padding=True)\n",
    "# Initialize our Trainer\n",
    "trainer = CTCTrainer(\n",
    "    model=model,\n",
    "    data_collator=data_collator,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_dataset if training_args.do_train else None,\n",
    "    eval_dataset=eval_dataset if training_args.do_eval else None,\n",
    "    tokenizer=processor.feature_extractor,\n",
    ")\n",
    "# Training\n",
    "if training_args.do_train:\n",
    "    if last_checkpoint is not None:\n",
    "        checkpoint = last_checkpoint\n",
    "    elif os.path.isdir(model_args.model_name_or_path):\n",
    "        checkpoint = model_args.model_name_or_path\n",
    "    else:\n",
    "        checkpoint = None\n",
    "    train_result = trainer.train(resume_from_checkpoint=checkpoint)\n",
    "    trainer.save_model()\n",
    "\n",
    "    # save the feature_extractor and the tokenizer\n",
    "    if is_main_process(training_args.local_rank):\n",
    "        processor.save_pretrained(training_args.output_dir)\n",
    "\n",
    "    metrics = train_result.metrics\n",
    "    max_train_samples = (\n",
    "        data_args.max_train_samples\n",
    "        if data_args.max_train_samples is not None\n",
    "        else len(train_dataset)\n",
    "    )\n",
    "    metrics[\"train_samples\"] = min(max_train_samples, len(train_dataset))\n",
    "\n",
    "    trainer.log_metrics(\"train\", metrics)\n",
    "    trainer.save_metrics(\"train\", metrics)\n",
    "    trainer.save_state()\n",
    "\n",
    "# Evaluation\n",
    "results = {}\n",
    "if training_args.do_eval:\n",
    "    logger.info(\"*** Evaluate ***\")\n",
    "    metrics = trainer.evaluate()\n",
    "    max_val_samples = (\n",
    "        data_args.max_val_samples\n",
    "        if data_args.max_val_samples is not None\n",
    "        else len(eval_dataset)\n",
    "    )\n",
    "    metrics[\"eval_samples\"] = min(max_val_samples, len(eval_dataset))\n",
    "\n",
    "    trainer.log_metrics(\"eval\", metrics)\n",
    "    trainer.save_metrics(\"eval\", metrics)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNOlyH4qin9EfRw8T6jJ/CZ",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "mount_file_id": "1K9Tq3M1zcHccwzjBI_wrdup2n_ETC0xA",
   "name": "GithHub_code_runner.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "cb837155d4bf090da51172bd16385c4d352f77e83b230ed743050e46498701be"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('arabic-speech-poetry-classification': virtualenv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
