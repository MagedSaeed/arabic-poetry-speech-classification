{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 205884,
     "status": "ok",
     "timestamp": 1635951380569,
     "user": {
      "displayName": "Maged Saeed",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghfl38dqLtgiKi2-s-gKPRT0lr9gXQd7UDqCF22lA=s64",
      "userId": "08011552846066909361"
     },
     "user_tz": -180
    },
    "id": "hLZPLV-qAmQq",
    "outputId": "2dadd197-cd05-4750-dc8c-4c1496e59cb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchaudio\n",
      "  Downloading torchaudio-0.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.9 MB 2.6 MB/s \n",
      "\u001b[?25hCollecting torch==1.10.0\n",
      "  Downloading torch-1.10.0-cp37-cp37m-manylinux1_x86_64.whl (881.9 MB)\n",
      "\u001b[K     |██████████████████████████████▎ | 834.1 MB 1.3 MB/s eta 0:00:38tcmalloc: large alloc 1147494400 bytes == 0x564eab682000 @  0x7f3bbf8ae615 0x564e714754cc 0x564e7155547a 0x564e714782ed 0x564e71569e1d 0x564e714ebe99 0x564e714e69ee 0x564e71479bda 0x564e714ebd00 0x564e714e69ee 0x564e71479bda 0x564e714e8737 0x564e7156ac66 0x564e714e7daf 0x564e7156ac66 0x564e714e7daf 0x564e7156ac66 0x564e714e7daf 0x564e7147a039 0x564e714bd409 0x564e71478c52 0x564e714ebc25 0x564e714e69ee 0x564e71479bda 0x564e714e8737 0x564e714e69ee 0x564e71479bda 0x564e714e7915 0x564e71479afa 0x564e714e7c0d 0x564e714e69ee\n",
      "\u001b[K     |████████████████████████████████| 881.9 MB 13 kB/s \n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.10.0->torchaudio) (3.7.4.3)\n",
      "Installing collected packages: torch, torchaudio\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.9.0+cu111\n",
      "    Uninstalling torch-1.9.0+cu111:\n",
      "      Successfully uninstalled torch-1.9.0+cu111\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchvision 0.10.0+cu111 requires torch==1.9.0, but you have torch 1.10.0 which is incompatible.\n",
      "torchtext 0.10.0 requires torch==1.9.0, but you have torch 1.10.0 which is incompatible.\u001b[0m\n",
      "Successfully installed torch-1.10.0 torchaudio-0.10.0\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.12.3-py3-none-any.whl (3.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.1 MB 3.1 MB/s \n",
      "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
      "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.3 MB 45.0 MB/s \n",
      "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
      "  Downloading huggingface_hub-0.1.0-py3-none-any.whl (59 kB)\n",
      "\u001b[K     |████████████████████████████████| 59 kB 6.6 MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
      "\u001b[K     |████████████████████████████████| 895 kB 57.3 MB/s \n",
      "\u001b[?25hCollecting pyyaml>=5.1\n",
      "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
      "\u001b[K     |████████████████████████████████| 596 kB 57.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
      "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
      "  Attempting uninstall: pyyaml\n",
      "    Found existing installation: PyYAML 3.13\n",
      "    Uninstalling PyYAML-3.13:\n",
      "      Successfully uninstalled PyYAML-3.13\n",
      "Successfully installed huggingface-hub-0.1.0 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.12.3\n",
      "Collecting datasets\n",
      "  Downloading datasets-1.15.1-py3-none-any.whl (290 kB)\n",
      "\u001b[K     |████████████████████████████████| 290 kB 3.1 MB/s \n",
      "\u001b[?25hCollecting xxhash\n",
      "  Downloading xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243 kB)\n",
      "\u001b[K     |████████████████████████████████| 243 kB 65.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.8.1)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.62.3)\n",
      "Collecting aiohttp\n",
      "  Downloading aiohttp-3.8.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 45.0 MB/s \n",
      "\u001b[?25hCollecting fsspec[http]>=2021.05.0\n",
      "  Downloading fsspec-2021.10.1-py3-none-any.whl (125 kB)\n",
      "\u001b[K     |████████████████████████████████| 125 kB 62.5 MB/s \n",
      "\u001b[?25hRequirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.1.0)\n",
      "Requirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.7.4.3)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (2.4.7)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.5.30)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
      "\u001b[K     |████████████████████████████████| 271 kB 60.5 MB/s \n",
      "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.0-py3-none-any.whl (6.1 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-5.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (160 kB)\n",
      "\u001b[K     |████████████████████████████████| 160 kB 59.1 MB/s \n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.7)\n",
      "Collecting asynctest==0.13.0\n",
      "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.2.0)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (192 kB)\n",
      "\u001b[K     |████████████████████████████████| 192 kB 67.6 MB/s \n",
      "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.6.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
      "Installing collected packages: multidict, frozenlist, yarl, asynctest, async-timeout, aiosignal, fsspec, aiohttp, xxhash, datasets\n",
      "Successfully installed aiohttp-3.8.0 aiosignal-1.2.0 async-timeout-4.0.0 asynctest-0.13.0 datasets-1.15.1 frozenlist-1.2.0 fsspec-2021.10.1 multidict-5.2.0 xxhash-2.0.2 yarl-1.7.2\n",
      "Collecting lang_trans\n",
      "  Downloading lang-trans-0.6.0.tar.gz (5.7 kB)\n",
      "Building wheels for collected packages: lang-trans\n",
      "  Building wheel for lang-trans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for lang-trans: filename=lang_trans-0.6.0-py3-none-any.whl size=6345 sha256=e0554d3c78254a142c538ea65d8e75a160324a85494671dddeda1997b626bc32\n",
      "  Stored in directory: /root/.cache/pip/wheels/ec/57/fe/a8a1df3409a81b298f4969f3e3084fe840033d7c03aec8e9e5\n",
      "Successfully built lang-trans\n",
      "Installing collected packages: lang-trans\n",
      "Successfully installed lang-trans-0.6.0\n",
      "Collecting arabic_reshaper\n",
      "  Downloading arabic_reshaper-2.1.3-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from arabic_reshaper) (57.4.0)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from arabic_reshaper) (0.16.0)\n",
      "Installing collected packages: arabic-reshaper\n",
      "Successfully installed arabic-reshaper-2.1.3\n",
      "Collecting python-bidi\n",
      "  Downloading python_bidi-0.4.2-py2.py3-none-any.whl (30 kB)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from python-bidi) (1.15.0)\n",
      "Installing collected packages: python-bidi\n",
      "Successfully installed python-bidi-0.4.2\n",
      "Collecting pydub\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Installing collected packages: pydub\n",
      "Successfully installed pydub-0.25.1\n",
      "Requirement already satisfied: soundfile in /usr/local/lib/python3.7/dist-packages (0.10.3.post1)\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile) (1.14.6)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile) (2.20)\n",
      "Collecting jiwer\n",
      "  Downloading jiwer-2.2.1-py3-none-any.whl (12 kB)\n",
      "Collecting python-Levenshtein==0.12.2\n",
      "  Downloading python-Levenshtein-0.12.2.tar.gz (50 kB)\n",
      "\u001b[K     |████████████████████████████████| 50 kB 2.1 MB/s \n",
      "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from python-Levenshtein==0.12.2->jiwer) (57.4.0)\n",
      "Building wheels for collected packages: python-Levenshtein\n",
      "  Building wheel for python-Levenshtein (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for python-Levenshtein: filename=python_Levenshtein-0.12.2-cp37-cp37m-linux_x86_64.whl size=149861 sha256=d130962b9738e9e8fb2e6ac0517e03d9c82a89e969e91f26d75fdf6dbe8f76cb\n",
      "  Stored in directory: /root/.cache/pip/wheels/05/5f/ca/7c4367734892581bb5ff896f15027a932c551080b2abd3e00d\n",
      "Successfully built python-Levenshtein\n",
      "Installing collected packages: python-Levenshtein, jiwer\n",
      "Successfully installed jiwer-2.2.1 python-Levenshtein-0.12.2\n",
      "Collecting PyArabic\n",
      "  Downloading PyArabic-0.6.14-py3-none-any.whl (126 kB)\n",
      "\u001b[K     |████████████████████████████████| 126 kB 4.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from PyArabic) (1.15.0)\n",
      "Installing collected packages: PyArabic\n",
      "Successfully installed PyArabic-0.6.14\n"
     ]
    }
   ],
   "source": [
    "!pip install torchaudio\n",
    "!pip install transformers\n",
    "!pip install datasets\n",
    "!pip install lang_trans\n",
    "!pip install arabic_reshaper\n",
    "!pip install python-bidi\n",
    "!pip install pydub\n",
    "!pip install soundfile\n",
    "!pip install jiwer\n",
    "!pip install PyArabic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 5872,
     "status": "ok",
     "timestamp": 1635951389881,
     "user": {
      "displayName": "Maged Saeed",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghfl38dqLtgiKi2-s-gKPRT0lr9gXQd7UDqCF22lA=s64",
      "userId": "08011552846066909361"
     },
     "user_tz": -180
    },
    "id": "7eFqbmnnAL-n"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import json\n",
    "import torch\n",
    "import jiwer\n",
    "import logging\n",
    "import librosa\n",
    "import datasets\n",
    "import itertools\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "import transformers\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "import seaborn as sns\n",
    "import torch.nn as nn\n",
    "import soundfile as sf\n",
    "import arabic_reshaper\n",
    "from pyarabic import araby\n",
    "from packaging import version\n",
    "from pydub import AudioSegment\n",
    "import matplotlib.pyplot as plt\n",
    "from .trainer import CTCTrainer\n",
    "from pydub.utils import mediainfo\n",
    "from argparse import ArgumentParser\n",
    "from torch.nn import functional as F\n",
    "from contextlib import contextmanager\n",
    "from bidi.algorithm import get_display\n",
    "from lang_trans.arabic import buckwalter\n",
    "from dataclasses import dataclass, field\n",
    "from datasets import load_dataset, Dataset\n",
    "from sklearn.metrics import accuracy_score\n",
    "from .models import Wav2Vec2ClassificationModel\n",
    "from .processors import CustomWav2Vec2Processor\n",
    "from typing import Any, Dict, List, Optional, Union\n",
    "from transformers import HfArgumentParser,TrainingArguments\n",
    "from .arg_parsers import DataTrainingArguments, ModelArguments, DataCollatorCTCWithPadding\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from transformers.trainer_utils import get_last_checkpoint, is_main_process\n",
    "from transformers import is_apex_available,set_seed ,Trainer,Wav2Vec2FeatureExtractor\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor, Wav2Vec2Model,Wav2Vec2PreTrainedModel\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 9944,
     "status": "ok",
     "timestamp": 1635951403156,
     "user": {
      "displayName": "Maged Saeed",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghfl38dqLtgiKi2-s-gKPRT0lr9gXQd7UDqCF22lA=s64",
      "userId": "08011552846066909361"
     },
     "user_tz": -180
    },
    "id": "B4BretRa_kHc"
   },
   "outputs": [],
   "source": [
    "!cp -r /content/drive/MyDrive/KFUPM-Master/ICS606/Dataset/All_poems.zip ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fWT8mSb1ADRU"
   },
   "outputs": [],
   "source": [
    "if os.path.exists('dataset'):\n",
    "  if len(os.listdir('dataset')) == 0:\n",
    "    os.system('unzip All_poems.zip -d dataset')\n",
    "else:\n",
    "  os.system('unzip All_poems.zip -d dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q0W2S-XtAGhi"
   },
   "outputs": [],
   "source": [
    "!mkdir -p dataset_wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G7f5oPvDCx4L"
   },
   "outputs": [],
   "source": [
    "!cp /content/drive/MyDrive/KFUPM-Master/ICS606/Dataset/testset.csv .\n",
    "!cp /content/drive/MyDrive/KFUPM-Master/ICS606/Dataset/trainset.csv .\n",
    "!cp /content/drive/MyDrive/KFUPM-Master/ICS606/Dataset/valset.csv ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jv2ZeRsUAIF9"
   },
   "outputs": [],
   "source": [
    "metadata_test_path = 'testset.csv'\n",
    "metadata_train_path = 'trainset.csv'\n",
    "metadata_val_path = 'valset.csv'\n",
    "dataset_folder = 'dataset'\n",
    "dataset_wav_folder = 'dataset_wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fytnRuUYAwnr"
   },
   "outputs": [],
   "source": [
    "train_metadata = pd.read_csv(metadata_train_path)\n",
    "test_metadata = pd.read_csv(metadata_test_path)\n",
    "val_metadata = pd.read_csv(metadata_val_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 596712,
     "status": "ok",
     "timestamp": 1634414983222,
     "user": {
      "displayName": "Maged Saeed",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghfl38dqLtgiKi2-s-gKPRT0lr9gXQd7UDqCF22lA=s64",
      "userId": "08011552846066909361"
     },
     "user_tz": -180
    },
    "id": "7_KVXrgqA11f",
    "outputId": "c9a0519e-5df3-4741-edbe-fe8d4e15f97e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{44100, 48000}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_rates = set()\n",
    "for file_path in itertools.chain(\n",
    "    train_metadata['Utterance name'],\n",
    "    test_metadata['Utterance name'],\n",
    "    val_metadata['Utterance name']\n",
    "  ):\n",
    "  complete_path = f'{dataset_folder}/{file_path}'\n",
    "  complete_wav_path = f'{dataset_wav_folder}/{file_path}'\n",
    "  # os.system(f'ffmpeg -i {complete_path} {complete_wav_path}')\n",
    "  audio = AudioSegment.from_file(complete_path)\n",
    "  sample_rates.add(audio.frame_rate)\n",
    "  audio.export(f'{dataset_wav_folder}/{file_path}', format='wav')\n",
    "sample_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6FyjHsokns8Z"
   },
   "outputs": [],
   "source": [
    "# the following can be used\n",
    "# https://beta.quod.ai/github/huggingface/transformers?question_modal=true&question_public_id=8757&from_search=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LjctTq9YGN0b"
   },
   "outputs": [],
   "source": [
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "if is_apex_available():\n",
    "    from apex import amp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if version.parse(torch.__version__) >= version.parse(\"1.6\"):\n",
    "    _is_native_amp_available = True\n",
    "    from torch.cuda.amp import autocast\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = HfArgumentParser(\n",
    "        (ModelArguments, DataTrainingArguments, TrainingArguments)\n",
    "    )\n",
    "if len(sys.argv) == 2 and sys.argv[1].endswith(\".json\"):\n",
    "    # If we pass only one argument to the script and it's the path to a json file,\n",
    "    # let's parse it to get our arguments.\n",
    "    model_args, data_args, training_args = parser.parse_json_file(\n",
    "        json_file=os.path.abspath(sys.argv[1])\n",
    "    )\n",
    "else:\n",
    "    model_args, data_args, training_args = parser.parse_args_into_dataclasses()\n",
    "# Detecting last checkpoint.\n",
    "last_checkpoint = None\n",
    "if (\n",
    "    os.path.isdir(training_args.output_dir)\n",
    "    and training_args.do_train\n",
    "    and not training_args.overwrite_output_dir\n",
    "):\n",
    "    last_checkpoint = get_last_checkpoint(training_args.output_dir)\n",
    "    if last_checkpoint is None and len(os.listdir(training_args.output_dir)) > 0:\n",
    "        raise ValueError(\n",
    "            f\"Output directory ({training_args.output_dir}) already exists and is not empty. \"\n",
    "            \"Use --overwrite_output_dir to overcome.\"\n",
    "        )\n",
    "    elif last_checkpoint is not None:\n",
    "        logger.info(\n",
    "            f\"Checkpoint detected, resuming training at {last_checkpoint}. To avoid this behavior, change \"\n",
    "            \"the `--output_dir` or add `--overwrite_output_dir` to train from scratch.\"\n",
    "        )\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    handlers=[logging.StreamHandler(sys.stdout)],\n",
    ")\n",
    "logger.setLevel(\n",
    "    logging.INFO if is_main_process(training_args.local_rank) else logging.WARN\n",
    ")\n",
    "\n",
    "# Log on each process the small summary:\n",
    "logger.warning(\n",
    "    f\"Process rank: {training_args.local_rank}, device: {training_args.device}, n_gpu: {training_args.n_gpu}\"\n",
    "    + f\"distributed training: {bool(training_args.local_rank != -1)}, 16-bits training: {training_args.fp16}\"\n",
    ")\n",
    "# Set the verbosity to info of the Transformers logger (on main process only):\n",
    "if is_main_process(training_args.local_rank):\n",
    "    transformers.utils.logging.set_verbosity_info()\n",
    "\n",
    "# Set seed before initializing model.\n",
    "set_seed(training_args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metadata = pd.read_csv(metadata_train_path)\n",
    "val_metadata = pd.read_csv(metadata_val_path)\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_metadata)\n",
    "eval_dataset = Dataset.from_pandas(val_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = Wav2Vec2FeatureExtractor(\n",
    "    feature_size=1,\n",
    "    sampling_rate=16_000,\n",
    "    padding_value=0.0,\n",
    "    do_normalize=True,\n",
    "    return_attention_mask=True,\n",
    ")\n",
    "processor = CustomWav2Vec2Processor(feature_extractor=feature_extractor)\n",
    "model = Wav2Vec2ClassificationModel.from_pretrained(\n",
    "    \"bakrianoo/sinai-voice-ar-stt\",\n",
    "    attention_dropout=0.01,\n",
    "    hidden_dropout=0.01,\n",
    "    feat_proj_dropout=0.0,\n",
    "    mask_time_prob=0.05,\n",
    "    layerdrop=0.01,\n",
    "    gradient_checkpointing=True,\n",
    "    num_attention_heads=4,\n",
    ")\n",
    "\n",
    "if model_args.freeze_feature_extractor:\n",
    "    model.freeze_feature_extractor()\n",
    "\n",
    "if data_args.max_train_samples is not None:\n",
    "    train_dataset = train_dataset.select(range(data_args.max_train_samples))\n",
    "\n",
    "if data_args.max_val_samples is not None:\n",
    "    eval_dataset = eval_dataset.select(range(data_args.max_val_samples))\n",
    "\n",
    "# Preprocessing the datasets.\n",
    "# We need to read the aduio files as arrays and tokenize the targets.\n",
    "resamplers = {  # The dataset contains all the uncommented sample rates\n",
    "    48000: torchaudio.transforms.Resample(48000, 16000),\n",
    "    44100: torchaudio.transforms.Resample(44100, 16000),\n",
    "    # 32000: torchaudio.transforms.Resample(32000, 16000),\n",
    "}\n",
    "\n",
    "labels = {\n",
    "    bahr: bahr_index\n",
    "    for bahr_index, bahr in enumerate(sorted(set(train_metadata[\"Bahr\"])))\n",
    "}\n",
    "print(\"labels are:\", labels)\n",
    "print(\"len:\", len(labels))\n",
    "\n",
    "def speech_file_to_array_fn(batch):\n",
    "    start = 0\n",
    "    stop = 20\n",
    "    srate = 16_000\n",
    "    speech_array, sampling_rate = torchaudio.load(\n",
    "        f'../dataset_wav/{batch[\"Utterance name\"]}'\n",
    "    )\n",
    "    speech_array = speech_array[0]\n",
    "    batch[\"speech\"] = resamplers[sampling_rate](speech_array).squeeze().numpy()\n",
    "    batch[\"sampling_rate\"] = srate\n",
    "    batch[\"parent\"] = labels[batch[\"Bahr\"]]\n",
    "    return batch\n",
    "\n",
    "train_dataset = train_dataset.map(\n",
    "    speech_file_to_array_fn,\n",
    "    remove_columns=train_dataset.column_names,\n",
    "    num_proc=data_args.preprocessing_num_workers,\n",
    ")\n",
    "eval_dataset = eval_dataset.map(\n",
    "    speech_file_to_array_fn,\n",
    "    remove_columns=eval_dataset.column_names,\n",
    "    num_proc=data_args.preprocessing_num_workers,\n",
    ")\n",
    "\n",
    "def prepare_dataset(batch):\n",
    "    # check that all files have the correct sampling rate\n",
    "    assert (\n",
    "        len(set(batch[\"sampling_rate\"])) == 1\n",
    "    ), f\"Make sure all inputs have the same sampling rate of {processor.feature_extractor.sampling_rate}.\"\n",
    "    batch[\"input_values\"] = processor(\n",
    "        batch[\"speech\"], sampling_rate=batch[\"sampling_rate\"][0]\n",
    "    ).input_values\n",
    "    batch[\"labels\"] = batch[\"parent\"]\n",
    "    return batch\n",
    "\n",
    "train_dataset = train_dataset.map(\n",
    "    prepare_dataset,\n",
    "    remove_columns=train_dataset.column_names,\n",
    "    batch_size=training_args.per_device_train_batch_size,\n",
    "    batched=True,\n",
    "    num_proc=data_args.preprocessing_num_workers,\n",
    ")\n",
    "eval_dataset = eval_dataset.map(\n",
    "    prepare_dataset,\n",
    "    remove_columns=eval_dataset.column_names,\n",
    "    batch_size=training_args.per_device_train_batch_size,\n",
    "    batched=True,\n",
    "    num_proc=data_args.preprocessing_num_workers,\n",
    ")\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids.argmax(-1)\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    report = classification_report(labels, preds)\n",
    "    matrix = confusion_matrix(labels, preds)\n",
    "    print(matrix)\n",
    "    return {\"accuracy\": acc}\n",
    "\n",
    "# Data collator\n",
    "data_collator = DataCollatorCTCWithPadding(processor=processor, padding=True)\n",
    "# Initialize our Trainer\n",
    "trainer = CTCTrainer(\n",
    "    model=model,\n",
    "    data_collator=data_collator,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_dataset if training_args.do_train else None,\n",
    "    eval_dataset=eval_dataset if training_args.do_eval else None,\n",
    "    tokenizer=processor.feature_extractor,\n",
    ")\n",
    "# Training\n",
    "if training_args.do_train:\n",
    "    if last_checkpoint is not None:\n",
    "        checkpoint = last_checkpoint\n",
    "    elif os.path.isdir(model_args.model_name_or_path):\n",
    "        checkpoint = model_args.model_name_or_path\n",
    "    else:\n",
    "        checkpoint = None\n",
    "    train_result = trainer.train(resume_from_checkpoint=checkpoint)\n",
    "    trainer.save_model()\n",
    "\n",
    "    # save the feature_extractor and the tokenizer\n",
    "    if is_main_process(training_args.local_rank):\n",
    "        processor.save_pretrained(training_args.output_dir)\n",
    "\n",
    "    metrics = train_result.metrics\n",
    "    max_train_samples = (\n",
    "        data_args.max_train_samples\n",
    "        if data_args.max_train_samples is not None\n",
    "        else len(train_dataset)\n",
    "    )\n",
    "    metrics[\"train_samples\"] = min(max_train_samples, len(train_dataset))\n",
    "\n",
    "    trainer.log_metrics(\"train\", metrics)\n",
    "    trainer.save_metrics(\"train\", metrics)\n",
    "    trainer.save_state()\n",
    "\n",
    "\n",
    "\n",
    "# Evaluation\n",
    "results = {}\n",
    "if training_args.do_eval:\n",
    "    logger.info(\"*** Evaluate ***\")\n",
    "    metrics = trainer.evaluate()\n",
    "    max_val_samples = (\n",
    "        data_args.max_val_samples\n",
    "        if data_args.max_val_samples is not None\n",
    "        else len(eval_dataset)\n",
    "    )\n",
    "    metrics[\"eval_samples\"] = min(max_val_samples, len(eval_dataset))\n",
    "\n",
    "    trainer.log_metrics(\"eval\", metrics)\n",
    "    trainer.save_metrics(\"eval\", metrics)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNOlyH4qin9EfRw8T6jJ/CZ",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "mount_file_id": "1K9Tq3M1zcHccwzjBI_wrdup2n_ETC0xA",
   "name": "GithHub_code_runner.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
